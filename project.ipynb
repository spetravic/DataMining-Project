{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominican-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "streaming-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # needed for running the notebook, uncomment if running for the first time\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handed-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('abstractdata5.csv', sep = '#', header = None)\n",
    "data.set_axis(['id', 'class', 'title', 'abstract'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-niagara",
   "metadata": {},
   "source": [
    "### 1. Baseline approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sporting-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and abstract and tokenize\n",
    "df = pd.DataFrame()\n",
    "df['text'] = data['title'] + \" \" + data['abstract']\n",
    "df['tokenized'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chubby-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['preprocessed'] = df['tokenized'].apply(lambda x: [item.lower() for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "controversial-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem\n",
    "porter = PorterStemmer()\n",
    "df['preprocessed'] = df['preprocessed'].apply(lambda x: [porter.stem(word) for word in x])\n",
    "df['preprocessed'] = df['preprocessed'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "df_tfidf = vectorizer.fit_transform(df['preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imposed-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply k-means\n",
    "kmeans = KMeans(n_clusters = 5, random_state = 42)\n",
    "kpreds = kmeans.fit_predict(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacterial-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NMI: 0.691\n"
     ]
    }
   ],
   "source": [
    "# NMI score\n",
    "baseline_score = normalized_mutual_info_score(data['class'], kpreds, average_method = 'geometric')\n",
    "print(\"Baseline NMI:\", np.round(baseline_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-thickness",
   "metadata": {},
   "source": [
    "### 2.  Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cloudy-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['text'] = data['title'] + \" \" + data['abstract']\n",
    "\n",
    "# load custom stopword file\n",
    "# taken from https://github.com/stopwords-iso/stopwords-en/blob/master/stopwords-en.txt\n",
    "file = open(\"stopwords-en.txt\", \"r\", encoding = 'utf-8')\n",
    "content = file.readlines()\n",
    "stop_words = [c.rstrip('\\n') for c in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial character substitution\n",
    "df1['text'] = df1['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "df1['text'] = df1['text'].apply(lambda x: x.replace(\"/\", \" \"))\n",
    "df1['text'] = df1['text'].apply(lambda x: x.replace(\"\\\\\", \" \"))\n",
    "df1['text'] = df1['text'].apply(lambda x: x.replace(\"-\", \" \"))\n",
    "\n",
    "# tokenize\n",
    "df1['tokenized'] = df1.apply(lambda row: nltk.word_tokenize(row['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brief-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words with non-ascii chars\n",
    "def is_ascii(w):\n",
    "    try:\n",
    "        w.encode().decode(\"us-ascii\")\n",
    "        return True\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "\n",
    "df1['preprocessed'] = df1['tokenized'].apply(lambda x: [item.lower() for item in x if is_ascii(item)])\n",
    "\n",
    "# remove stopwords, punctuation, digits\n",
    "df1['preprocessed'] = df1['preprocessed'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df1['preprocessed'] = df1['preprocessed'].apply(lambda x: [item for item in x if item not in string.punctuation])\n",
    "df1['preprocessed'] = df1['preprocessed'].apply(lambda x: [item for item in x if not any(c.isdigit() for c in item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wired-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "snowball = SnowballStemmer(language='english')\n",
    "df1['preprocessed'] = df1['preprocessed'].apply(lambda x: [snowball.stem(word) for word in x])\n",
    "df1['preprocessed'] = df1['preprocessed'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coupled-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf representation\n",
    "cv = CountVectorizer(ngram_range = (1, 3), min_df = 0.003)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "df1_cv = cv.fit_transform(df1['preprocessed'])\n",
    "df1_tfidf = tfidf.fit_transform(df1_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "liked-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform SVD and normalization\n",
    "svd = TruncatedSVD(n_components = 5, random_state = 42)\n",
    "normalizer = Normalizer()\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "df1_tfidf_transformed = lsa.fit_transform(df1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "guilty-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply KMeans and spectral clustering\n",
    "spectral = SpectralClustering(n_clusters = 5, random_state = 42, affinity = 'rbf', gamma = 0.05)\n",
    "\n",
    "kpreds1 = kmeans.fit_predict(df1_tfidf_transformed)\n",
    "spreds = spectral.fit_predict(df1_tfidf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "retired-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans NMI: 0.813\n",
      "Spectral clustering NMI: 0.815\n"
     ]
    }
   ],
   "source": [
    "# NMI scores\n",
    "kscore = normalized_mutual_info_score(data['class'], kpreds1, average_method = 'geometric')\n",
    "sscore = normalized_mutual_info_score(data['class'], spreds, average_method = 'geometric')\n",
    "\n",
    "print(\"Kmeans NMI:\", np.round(kscore, 3))\n",
    "print(\"Spectral clustering NMI:\", np.round(sscore, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-major",
   "metadata": {},
   "source": [
    "### 3. Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exotic-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "robot       862\n",
      "control     339\n",
      "base        197\n",
      "perform     190\n",
      "model       181\n",
      "task        158\n",
      "propos      151\n",
      "develop     144\n",
      "design      142\n",
      "learn       135\n",
      "approach    129\n",
      "method      121\n",
      "environ     119\n",
      "soft        116\n",
      "studi       115\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Topic 2\n",
      "databas          694\n",
      "data             607\n",
      "relat            389\n",
      "queri            279\n",
      "relat databas    257\n",
      "model            211\n",
      "base             195\n",
      "approach         162\n",
      "propos           141\n",
      "process          138\n",
      "paper            116\n",
      "system           116\n",
      "sql              111\n",
      "manag            109\n",
      "develop          108\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Topic 3\n",
      "secur           697\n",
      "base            401\n",
      "propos          368\n",
      "scheme          335\n",
      "data            324\n",
      "encrypt         309\n",
      "key             304\n",
      "quantum         257\n",
      "cryptographi    251\n",
      "protocol        240\n",
      "comput          235\n",
      "attack          231\n",
      "algorithm       214\n",
      "implement       188\n",
      "effici          159\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Topic 4\n",
      "compil       631\n",
      "program      372\n",
      "code         264\n",
      "comput       244\n",
      "languag      226\n",
      "optim        216\n",
      "base         216\n",
      "time         202\n",
      "applic       188\n",
      "implement    176\n",
      "algorithm    176\n",
      "paper        175\n",
      "graph        175\n",
      "memori       169\n",
      "perform      168\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Topic 5\n",
      "imag         685\n",
      "method       559\n",
      "base         542\n",
      "detect       487\n",
      "model        465\n",
      "propos       464\n",
      "learn        381\n",
      "vision       373\n",
      "network      329\n",
      "perform      326\n",
      "data         288\n",
      "algorithm    281\n",
      "object       275\n",
      "deep         254\n",
      "featur       247\n",
      "dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf = pd.DataFrame(df1_cv.toarray(), columns = cv.get_feature_names_out())\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Topic\", i + 1)\n",
    "    \n",
    "    words = tf[spreds == i].sum().sort_values(ascending=False)[:15]\n",
    "    print(words, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
